#!/usr/bin/env python3
"""
Rosbag elemz≈ë script - T3 teszt /objects topic elemz√©se
Meghat√°rozza hogy scan-enk√©nt h√°ny objektum volt detekt√°lva
"""

import sqlite3
import sys
from pathlib import Path
import json
from collections import defaultdict

def analyze_rosbag(bag_path):
    """
    Elemzi a rosbag /objects topic-j√°t √©s statisztik√°kat k√©sz√≠t
    """
    print(f"üìä Rosbag elemz√©s: {bag_path}")
    print("=" * 60)
    
    # MCAP f√°jl megkeres√©se
    bag_dir = Path(bag_path)
    mcap_files = list(bag_dir.glob("*.mcap"))
    
    if not mcap_files:
        print(f"‚ùå Nem tal√°lhat√≥ MCAP f√°jl: {bag_dir}")
        return
    
    mcap_file = mcap_files[0]
    print(f"‚úÖ MCAP f√°jl: {mcap_file.name}\n")
    
    try:
        # MCAP form√°tum sqlite3 metadata-val
        db_path = bag_dir / "metadata.db"
        
        if not db_path.exists():
            print("‚ö†Ô∏è Nincs metadata.db, pr√≥b√°lom k√∂zvetlen√ºl olvasni...")
            analyze_mcap_direct(mcap_file)
            return
            
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # Topic inform√°ci√≥k
        cursor.execute("SELECT name, type, serialization_format FROM topics")
        topics = cursor.fetchall()
        
        print("üìã Topicok:")
        for topic in topics:
            print(f"  - {topic[0]} ({topic[1]})")
        
        print()
        
        # /objects √ºzenetek elemz√©se
        cursor.execute("""
            SELECT m.timestamp, m.data 
            FROM messages m
            JOIN topics t ON m.topic_id = t.id
            WHERE t.name = '/objects'
            ORDER BY m.timestamp
        """)
        
        messages = cursor.fetchall()
        print(f"‚úÖ /objects √ºzenetek: {len(messages)} db\n")
        
        if len(messages) == 0:
            print("‚ùå Nincs /objects √ºzenet a rosbag-ben!")
            conn.close()
            return
        
        # Objektumsz√°mok statisztik√°ja
        object_counts = []
        
        for idx, (timestamp, data) in enumerate(messages):
            # PoseArray strukt√∫ra: header + poses t√∂mb
            # Egyszer≈± sz√°mol√°s: poses t√∂mb hossza
            # (CDR szerializ√°ci√≥val bonyolult lenne full parse)
            
            # Egyszer≈±s√≠tett becsl√©s: minden √ºzenet objektumsz√°m√°t becs√ºlj√ºk
            # A data m√©rete alapj√°n (approxim√°ci√≥)
            data_size = len(data)
            
            # PoseArray poses: minden Pose ~56 byte (position 3*8 + orientation 4*8)
            # Header ~30-40 byte
            # Becs√ºlt objektumsz√°m: (data_size - 50) / 56
            
            estimated_objects = max(0, (data_size - 50) // 56)
            object_counts.append(estimated_objects)
            
            if idx < 5:  # Els≈ë 5 √ºzenet r√©szletei
                print(f"  [{idx+1}] Timestamp: {timestamp}, Data m√©ret: {data_size} byte, Becs√ºlt obj: {estimated_objects}")
        
        conn.close()
        
        # Statisztik√°k
        print("\n" + "=" * 60)
        print("üìà STATISZTIK√ÅK")
        print("=" * 60)
        
        if object_counts:
            avg_objects = sum(object_counts) / len(object_counts)
            min_objects = min(object_counts)
            max_objects = max(object_counts)
            
            print(f"√ñsszesen √ºzenetek: {len(object_counts)}")
            print(f"√Åtlagos objektumsz√°m/scan: {avg_objects:.2f}")
            print(f"Minimum objektumsz√°m: {min_objects}")
            print(f"Maximum objektumsz√°m: {max_objects}")
            
            # Eloszl√°s
            count_dist = defaultdict(int)
            for count in object_counts:
                count_dist[count] += 1
            
            print("\nüìä Objektumsz√°m eloszl√°s:")
            for obj_count in sorted(count_dist.keys()):
                freq = count_dist[obj_count]
                percent = (freq / len(object_counts)) * 100
                bar = "‚ñà" * int(percent / 2)
                print(f"  {obj_count} objektum: {freq:3d} scan ({percent:5.1f}%) {bar}")
        
    except Exception as e:
        print(f"‚ùå Hiba: {e}")
        import traceback
        traceback.print_exc()

def analyze_mcap_direct(mcap_file):
    """
    K√∂zvetlen√ºl MCAP f√°jl olvas√°sa (ha van mcap library)
    """
    print("‚ö†Ô∏è Pr√≥b√°lom mcap library-vel...")
    try:
        from mcap.reader import make_reader
        
        with open(mcap_file, "rb") as f:
            reader = make_reader(f)
            
            objects_messages = []
            
            for schema, channel, message in reader.iter_messages(topics=["/objects"]):
                objects_messages.append(message)
            
            print(f"‚úÖ /objects √ºzenetek: {len(objects_messages)} db")
            
            # Egyszer≈± statisztika data m√©ret alapj√°n
            for idx, msg in enumerate(objects_messages[:5]):
                data_size = len(msg.data)
                estimated_objects = max(0, (data_size - 50) // 56)
                print(f"  [{idx+1}] Data m√©ret: {data_size} byte, Becs√ºlt obj: {estimated_objects}")
            
    except ImportError:
        print("‚ùå mcap library nincs telep√≠tve!")
        print("Telep√≠tsd: pip install mcap")
    except Exception as e:
        print(f"‚ùå Hiba mcap olvas√°sn√°l: {e}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Haszn√°lat: python3 analyze_rosbag.py <rosbag_path>")
        print("P√©lda: python3 analyze_rosbag.py test_run_stress_v2")
        sys.exit(1)
    
    bag_path = sys.argv[1]
    analyze_rosbag(bag_path)
